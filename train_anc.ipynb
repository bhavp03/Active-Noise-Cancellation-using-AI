{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu...\n",
      "Epoch [1/10], Step [100/724], Loss: 0.0091\n",
      "Epoch [1/10], Step [200/724], Loss: 0.0061\n",
      "Epoch [1/10], Step [300/724], Loss: 0.0039\n",
      "Epoch [1/10], Step [400/724], Loss: 0.0029\n",
      "Epoch [1/10], Step [500/724], Loss: 0.0026\n",
      "Epoch [1/10], Step [600/724], Loss: 0.0019\n",
      "Epoch [1/10], Step [700/724], Loss: 0.0022\n",
      "Epoch [1/10] completed in 1660.94 seconds. Avg Loss: 0.0180\n",
      "Epoch [2/10], Step [100/724], Loss: 0.0022\n",
      "Epoch [2/10], Step [200/724], Loss: 0.0017\n",
      "Epoch [2/10], Step [300/724], Loss: 0.0016\n",
      "Epoch [2/10], Step [400/724], Loss: 0.0018\n",
      "Epoch [2/10], Step [500/724], Loss: 0.0019\n",
      "Epoch [2/10], Step [600/724], Loss: 0.0013\n",
      "Epoch [2/10], Step [700/724], Loss: 0.0012\n",
      "Epoch [2/10] completed in 1546.90 seconds. Avg Loss: 0.0016\n",
      "Epoch [3/10], Step [100/724], Loss: 0.0015\n",
      "Epoch [3/10], Step [200/724], Loss: 0.0010\n",
      "Epoch [3/10], Step [300/724], Loss: 0.0010\n",
      "Epoch [3/10], Step [400/724], Loss: 0.0009\n",
      "Epoch [3/10], Step [500/724], Loss: 0.0015\n",
      "Epoch [3/10], Step [600/724], Loss: 0.0007\n",
      "Epoch [3/10], Step [700/724], Loss: 0.0017\n",
      "Epoch [3/10] completed in 1579.55 seconds. Avg Loss: 0.0014\n",
      "Epoch [4/10], Step [100/724], Loss: 0.0015\n",
      "Epoch [4/10], Step [200/724], Loss: 0.0012\n",
      "Epoch [4/10], Step [300/724], Loss: 0.0015\n",
      "Epoch [4/10], Step [400/724], Loss: 0.0011\n",
      "Epoch [4/10], Step [500/724], Loss: 0.0010\n",
      "Epoch [4/10], Step [600/724], Loss: 0.0011\n",
      "Epoch [4/10], Step [700/724], Loss: 0.0014\n",
      "Epoch [4/10] completed in 1452.76 seconds. Avg Loss: 0.0013\n",
      "Epoch [5/10], Step [100/724], Loss: 0.0009\n",
      "Epoch [5/10], Step [200/724], Loss: 0.0011\n",
      "Epoch [5/10], Step [300/724], Loss: 0.0016\n",
      "Epoch [5/10], Step [400/724], Loss: 0.0013\n",
      "Epoch [5/10], Step [500/724], Loss: 0.0013\n",
      "Epoch [5/10], Step [600/724], Loss: 0.0011\n",
      "Epoch [5/10], Step [700/724], Loss: 0.0015\n",
      "Epoch [5/10] completed in 1487.27 seconds. Avg Loss: 0.0012\n",
      "Epoch [6/10], Step [100/724], Loss: 0.0011\n",
      "Epoch [6/10], Step [200/724], Loss: 0.0017\n",
      "Epoch [6/10], Step [300/724], Loss: 0.0015\n",
      "Epoch [6/10], Step [400/724], Loss: 0.0013\n",
      "Epoch [6/10], Step [500/724], Loss: 0.0008\n",
      "Epoch [6/10], Step [600/724], Loss: 0.0019\n",
      "Epoch [6/10], Step [700/724], Loss: 0.0009\n",
      "Epoch [6/10] completed in 1509.37 seconds. Avg Loss: 0.0012\n",
      "Epoch [7/10], Step [100/724], Loss: 0.0012\n",
      "Epoch [7/10], Step [200/724], Loss: 0.0011\n",
      "Epoch [7/10], Step [300/724], Loss: 0.0011\n",
      "Epoch [7/10], Step [400/724], Loss: 0.0011\n",
      "Epoch [7/10], Step [500/724], Loss: 0.0014\n",
      "Epoch [7/10], Step [600/724], Loss: 0.0011\n",
      "Epoch [7/10], Step [700/724], Loss: 0.0013\n",
      "Epoch [7/10] completed in 1669.98 seconds. Avg Loss: 0.0012\n",
      "Epoch [8/10], Step [100/724], Loss: 0.0010\n",
      "Epoch [8/10], Step [200/724], Loss: 0.0019\n",
      "Epoch [8/10], Step [300/724], Loss: 0.0010\n",
      "Epoch [8/10], Step [400/724], Loss: 0.0011\n",
      "Epoch [8/10], Step [500/724], Loss: 0.0010\n",
      "Epoch [8/10], Step [600/724], Loss: 0.0009\n",
      "Epoch [8/10], Step [700/724], Loss: 0.0015\n",
      "Epoch [8/10] completed in 2063.91 seconds. Avg Loss: 0.0012\n",
      "Epoch [9/10], Step [100/724], Loss: 0.0014\n",
      "Epoch [9/10], Step [200/724], Loss: 0.0013\n",
      "Epoch [9/10], Step [300/724], Loss: 0.0011\n",
      "Epoch [9/10], Step [400/724], Loss: 0.0014\n",
      "Epoch [9/10], Step [500/724], Loss: 0.0013\n",
      "Epoch [9/10], Step [600/724], Loss: 0.0009\n",
      "Epoch [9/10], Step [700/724], Loss: 0.0010\n",
      "Epoch [9/10] completed in 1438.45 seconds. Avg Loss: 0.0012\n",
      "Epoch [10/10], Step [100/724], Loss: 0.0009\n",
      "Epoch [10/10], Step [200/724], Loss: 0.0013\n",
      "Epoch [10/10], Step [300/724], Loss: 0.0011\n",
      "Epoch [10/10], Step [400/724], Loss: 0.0017\n",
      "Epoch [10/10], Step [500/724], Loss: 0.0011\n",
      "Epoch [10/10], Step [600/724], Loss: 0.0010\n",
      "Epoch [10/10], Step [700/724], Loss: 0.0006\n",
      "Epoch [10/10] completed in 1435.56 seconds. Avg Loss: 0.0011\n",
      "Training completed. Model saved as best_model_cpu.pth. Total time: 15844.75 seconds.\n"
     ]
    }
   ],
   "source": [
    "            import time\n",
    "            import os\n",
    "            import torch\n",
    "            import torch.optim as optim\n",
    "            from torch.utils.data import DataLoader\n",
    "            from unet_anc_model import UNetANC  # Ensure this matches the path to your model definition file\n",
    "            from dataset.dataset import NoisyCleanAudioDataset  # Ensure this matches the dataset class you're using\n",
    "            import numpy as np\n",
    "            import librosa\n",
    "\n",
    "            # Update these paths with your dataset folders\n",
    "            noisy_folder = \"D:/ANC/dataset/pnoisy_trainset_28spk_wav\"  # Replace with your noisy dataset path\n",
    "            clean_folder = \"D:/ANC/dataset/clean_trainset_28spk_wav\"  # Replace with your clean dataset path\n",
    "\n",
    "            # Ensure these paths are correct\n",
    "            if not os.path.exists(noisy_folder) or not os.path.exists(clean_folder):\n",
    "                raise FileNotFoundError(f\"Dataset folders not found at {noisy_folder} or {clean_folder}. Ensure the paths are correct.\")\n",
    "\n",
    "            # **Model Training**\n",
    "            def train_model():\n",
    "                device = torch.device(\"cpu\")  # For Intel Iris Xe GPU\n",
    "                model = UNetANC().to(device)\n",
    "                \n",
    "                # Dataset loading\n",
    "                dataset = NoisyCleanAudioDataset(noisy_folder, clean_folder)\n",
    "                dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "                \n",
    "                # Optimizer and loss function\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "                criterion = torch.nn.MSELoss()\n",
    "                \n",
    "                num_epochs = 10  # Adjust the number of epochs as necessary\n",
    "                \n",
    "                # Start training\n",
    "                print(f\"Training on {device}...\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                for epoch in range(num_epochs):\n",
    "                    epoch_start_time = time.time()  # Track time for each epoch\n",
    "                    model.train()  # Set the model to training mode\n",
    "                    \n",
    "                    total_loss = 0\n",
    "                    for i, (noisy, clean) in enumerate(dataloader):\n",
    "                        noisy = noisy.to(device)\n",
    "                        clean = clean.to(device)\n",
    "                        \n",
    "                        # Zero the gradients\n",
    "                        optimizer.zero_grad()\n",
    "                        \n",
    "                        # Forward pass\n",
    "                        output = model(noisy)\n",
    "                        \n",
    "                        # Calculate loss\n",
    "                        loss = criterion(output, clean)\n",
    "                        \n",
    "                        # Backpropagation\n",
    "                        loss.backward()\n",
    "                        \n",
    "                        # Update the weights\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        # Track the loss for this batch\n",
    "                        total_loss += loss.item()\n",
    "                        \n",
    "                        # Print loss at specified intervals\n",
    "                        if (i + 1) % 100 == 0:  # Print every 100 batches\n",
    "                            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "                    \n",
    "                    # Average loss for the epoch\n",
    "                    avg_loss = total_loss / len(dataloader)\n",
    "                    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed in {time.time() - epoch_start_time:.2f} seconds. Avg Loss: {avg_loss:.4f}\")\n",
    "                \n",
    "                # Save the model after training\n",
    "                model_save_path = \"best_model_cpu.pth\"\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                print(f\"Training completed. Model saved as {model_save_path}. Total time: {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "            if __name__ == \"__main__\":\n",
    "                train_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
