{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhavy\\AppData\\Local\\Temp\\ipykernel_2144\\4182191972.py:103: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Recording...\n",
      "Recording saved as recorded_noisy.wav\n",
      "Processed 6 chunks from the noisy audio.\n",
      "Denoising chunk 1/6\n",
      "Denoising chunk 2/6\n",
      "Denoising chunk 3/6\n",
      "Denoising chunk 4/6\n",
      "Denoising chunk 5/6\n",
      "Denoising chunk 6/6\n",
      "Denoised audio saved as denoised_audio.wav\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_waveform_spectrogram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 133\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[0;32m    132\u001b[0m noisy_audio, _ \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecorded_noisy.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m \u001b[43mplot_waveform_spectrogram\u001b[49m(noisy_audio, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoisy Audio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m plot_waveform_spectrogram(denoised_audio, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDenoised Audio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_waveform_spectrogram' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from unet_anc_model import UNetANC\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "# **Preprocessing Function**\n",
    "def preprocess_audio(file_path, sr=16000, chunk_length=32000, overlap=1600):\n",
    "    \"\"\"\n",
    "    Preprocess the audio into overlapping chunks for model input.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        sr (int): Sampling rate.\n",
    "        chunk_length (int): Length of each chunk in samples.\n",
    "        overlap (int): Overlap between consecutive chunks in samples.\n",
    "    \n",
    "    Returns:\n",
    "        chunks (list): List of torch tensors containing audio chunks.\n",
    "        original_length (int): Original audio length in samples.\n",
    "    \"\"\"\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    original_length = len(audio)  # Store the original audio length\n",
    "    chunks = []\n",
    "\n",
    "    # Create overlapping chunks\n",
    "    for start in range(0, original_length, chunk_length - overlap):\n",
    "        end = start + chunk_length\n",
    "        chunk = audio[start:end]\n",
    "        if len(chunk) < chunk_length:\n",
    "            chunk = np.pad(chunk, (0, chunk_length - len(chunk)), mode='constant')\n",
    "        chunks.append(torch.tensor(chunk, dtype=torch.float32).unsqueeze(0).unsqueeze(0))  # Add batch and channel dims\n",
    "\n",
    "    return chunks, original_length\n",
    "\n",
    "\n",
    "# **Postprocessing Function**\n",
    "def postprocess_audio(denoised_chunks, original_length):\n",
    "    \"\"\"\n",
    "    Combine the denoised chunks back into a single audio waveform and truncate to the original length.\n",
    "    \n",
    "    Parameters:\n",
    "        denoised_chunks (list): List of numpy arrays representing denoised audio chunks.\n",
    "        original_length (int): The original length of the audio signal.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed audio signal of the original length.\n",
    "    \"\"\"\n",
    "    # Concatenate all chunks\n",
    "    combined_audio = np.concatenate(denoised_chunks)\n",
    "    \n",
    "    # Truncate to the original length\n",
    "    return combined_audio[:original_length].astype(np.float32)\n",
    "\n",
    "# **Audio Recording**\n",
    "def record_audio(filename=\"recorded_noisy.wav\", duration=10, sr=16000):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * sr), samplerate=sr, channels=1, dtype='float32')\n",
    "    sd.wait()\n",
    "    write(filename, sr, np.squeeze(audio))\n",
    "    print(f\"Recording saved as {filename}\")\n",
    "\n",
    "# **Denoising Function**\n",
    "def denoise_audio(model, noisy_chunks, device):\n",
    "    \"\"\"\n",
    "    Perform denoising on a list of audio chunks using the model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: The trained PyTorch model for denoising.\n",
    "        noisy_chunks (list): List of audio chunks (tensors).\n",
    "        device: The device to run the model on (CPU/GPU).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of denoised audio chunks (numpy arrays).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    denoised_chunks = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, chunk in enumerate(noisy_chunks):\n",
    "            print(f\"Denoising chunk {i + 1}/{len(noisy_chunks)}\")\n",
    "            chunk = chunk.to(device)\n",
    "            denoised_chunk = model(chunk).squeeze().cpu().numpy()\n",
    "            denoised_chunks.append(denoised_chunk)\n",
    "\n",
    "    return denoised_chunks\n",
    "\n",
    "\n",
    "# **Main Script**\n",
    "if __name__ == \"__main__\":\n",
    "    # Define model and device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = UNetANC().to(device)\n",
    "\n",
    "    # Load trained model weights\n",
    "    model_path = \"best_model_cpu.pth\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {model_path}. Ensure the file exists.\")\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    print(\"Model loaded successfully!\")\n",
    "\n",
    "    # Record or load noisy audio\n",
    "    record_audio()  # Records a 10-second noisy audio file named \"recorded_noisy.wav\"\n",
    "\n",
    "    # Preprocess the recorded noisy audio\n",
    "    noisy_chunks, original_length = preprocess_audio(\"recorded_noisy.wav\")\n",
    "    print(f\"Processed {len(noisy_chunks)} chunks from the noisy audio.\")\n",
    "\n",
    "    # Perform denoising\n",
    "    denoised_chunks = denoise_audio(model, noisy_chunks, device)\n",
    "\n",
    "    # Postprocess to reconstruct the full audio\n",
    "    denoised_audio = postprocess_audio(denoised_chunks, original_length)\n",
    "\n",
    "    if len(denoised_audio.shape) != 1 or not np.issubdtype(denoised_audio.dtype, np.floating):\n",
    "        raise ValueError(\"Denoised audio must be a 1D float32 array.\")\n",
    "\n",
    "    # Save the denoised audio\n",
    "    output_file = \"denoised_audio.wav\"\n",
    "    sf.write(output_file, denoised_audio, 16000)\n",
    "    print(f\"Denoised audio saved as {output_file}\")\n",
    "\n",
    "    # Plot results\n",
    "    noisy_audio, _ = librosa.load(\"recorded_noisy.wav\", sr=16000)\n",
    "    plot_waveform_spectrogram(noisy_audio, title=\"Noisy Audio\")\n",
    "    plot_waveform_spectrogram(denoised_audio, title=\"Denoised Audio\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
